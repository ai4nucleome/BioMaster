[
    {
        "content": "EIGENSOFT 5.0 changes include:\n- New option lsqproject for PCA projection with large amounts of missing data.\n- New options grmoutname and grmbinary to output genetic relationship matrix, compatible with GCTA software (v1.13).\n- Expanded options for LD regression in computing genetic relationship matrix.\n\nSmartPCA description:\nSmartPCA runs Principal Components Analysis on input genotype data and outputs principal components (eigenvectors) and eigenvalues. The principal components are useful for a variety of tasks, including identifying population structure and correcting for population stratification in genetic association studies.\n\nProgram-specific details and input formats:\nSmartPCA supports five different input formats. See ../CONVERTF/README for documentation on using the convertf program to convert between formats.\n\nSyntax for SmartPCA:\n../bin/smartpca -p parfile\n\nInput format details:\n- genotypename: Input genotype file (in any format: see ../CONVERTF/README).\n- snpname: Input SNP file (in any format: see ../CONVERTF/README).\n- indivname: Input individual file (in any format: see ../CONVERTF/README).\n- evecoutname: Output file of eigenvectors (see numoutevec parameter below).\n- evaloutname: Output file of all eigenvalues.\n\nOptional parameters:\n- numoutevec: Number of eigenvectors to output. Default is 10.\n- numoutlieriter: Maximum number of outlier removal iterations. Default is 5. To turn off outlier removal, set this parameter to 0.\n- grmoutname: Output file prefix containing the lower-triangular of the genetic relatedness matrix, compatible with GCTA software.\n\nOther relevant programs include:\n- ploteig (for plotting the top two principal components).\n- twstats (for computing Tracy-Widom statistics to evaluate statistical significance of each principal component).A complete example of implementation includes:which python \n conda install -y eigensoft\necho 'genotypename: ./data/1000GP_pruned. bed' > ./output/098/smartpca.par\necho 'snpname: ./data/1000GP_pruned. bim' >> ./output/098/smartpca.par\necho 'indivname: ./data/1000GP_pruned. fam' >> ./output/098/smartpca.par\necho 'evecoutname: ./output/098/smartpca. evec' >> ./output/098/smartpca.par\necho 'evaloutname: ./output/098/smartpca. eval' >> ./output/098/smartpca.par\necho 'numoutevec: 10' >> ./output/098/smartpca.par\necho 'numoutlieriter: 5' >> ./output/098/smartpca.par\nsmartpca -p ./output/098/smartpca.par",
        "metadata": {
            "source": "smartPCA",
            "page": 1
        }
    },
    {
        "content": "Detailed Metagenomic Analysis Workflow must include:Step1: load main function: source('00.func_v2.R'). Description: The document '00.func_v2.R' contains necessary R packages along with their installation commands, and a pre-written main function. Subsequent use only requires sourcing the file with `source(\"00.func_v2.R\")`.Step2: create_phyloseq function: Description: create phyloseq-class object; specify group (g1, g2) variables and subset specified levels (g1.level, g2.level); filter taxonomy by detection and prevalence cutoff. Parameters: otu_table (OTU table), tax_table (taxonomy table), sam_data (samples metadata), tax_level (select specified taxonomy level), g1 (group1 in sample metadata), g1.level (subgroups level included in group1), g2 (group2 in sample metadata), g2.level (subgroups level included in group2), detection (detection cutoff), prevalence (prevalence cutoff), rel (Transformation to apply. The options include: 'compositional' (ie relative abundance), 'Z', 'log10', 'log10p', 'hellinger', 'identity', 'clr', 'alr'), tidy_taxonomy (Clean up the taxonomic table to make taxonomic assignments consistent). Expected Output: phyloseq-class object. Tools Used: create_phyloseq function.Step3: plot_detection_prevalence function: Description: Calculates the community core microbita and visualization. Determine members of the core microbiota with given abundance and prevalences. Parameters:   ps (phyloseq object), min_prevalence (minimum prevalence cutoff), step_detection (Set the number of steps for detection). Expected Output: filtered phyloseq object and core microbita figure plot. Tools Used: plot_detection_prevalence function.Step4: plot_comp function: Description: Plot taxon abundance for microbiome composition. Parameters: ps (phyloseq object), tax_level (select specified taxonomy level), strata (Specifies a faceted variable), groupmean (calculate mean abundance for each group), ntaxa (how many taxa are selected to show), sort_bacteria (Select the number of bacteria to arrange the sample), clustering (whether order samples by the clustering), clustering_plot (whether add clustering plot), use_alluvium (whether add alluvium plot). Expected Output: Composition figure plot. Tools Used: plot_comp function.Step5: cal_alpha function: Description: analyzing alpha diversity in ecosystems, including the calculation of various richness, evenness, diversity, dominance, and rarity indices, along with methods for visualizing these measures and testing differences in alpha diversity between groups. Parameters: ps (phyloseq object), group (A string indicating the variable for group identifiers), strata (A string indicating the variable for strata identifiers), method_test (the name of the statistical test (e.g. t.test, wilcox.test etc.)), signif_label (whether show the p-value as labels: c('***'=0.001, '**'=0.01, '*'=0.05)), adj.vars (Specify adjust variables of sample metadata). Expected Output: Alpha diversity index table (res_alpha$table) and figure plots (res_alpha$observed, res_alpha$chao1, res_alpha$diversity_shannon, res_alpha$diversity_gini_simpson, etc.). Tools Used: cal_alpha function.Step6: cal_pca function: Description: Performs a principal components analysis (PCA). Parameters: ps (phyloseq object), group (A string indicating the variable for group identifiers), center (whether the variables should be shifted to be zero centered), scale (whether the variables should be scaled to have unit variance). Expected Output: PCA  components table (res_pca$table) and figure plots (res_pca$pca_biplot, res_pca$pca_ind, res_pca$pca_contrib1, res_pca$pca_contrib2). Tools Used: cal_pca function.Step7: cal_dist function: Description: Calculate dissimilarity matrix, anosim and PERMANOVA analysis. Parameters: ps (phyloseq object), method (Dissimilarity index, one of c('manhattan', 'euclidean', 'canberra', 'clark', 'bray', 'kulczynski', 'jaccard', 'gower', 'altGower', 'morisita', 'horn', 'mountford', 'raup', 'binomial', 'chao', 'cao', 'mahalanobis', 'chisq', 'chord', 'hellinger', 'aitchison','robust.aitchison')), group (A string indicating the variable for group identifiers for anosim and PERMANOVA analysis), adj.vars (adjust variables of sample metadata. Note: This feature is yet to be verified). Expected Output: A list contains Dissimilarity matrix (res_dist$dist), anosim result (res_dist$anosim) and PERMANOVA RESULT (res_dist$PERMANOVA). Tools Used: cal_dist function.Step8: cal_ordination function: Description: Perform an ordination on phyloseq data. Parameters: ps (phyloseq object), dist (a pre-computed dist-class object), method (several commonly-used ordination methods. Currently supported method options are: c('DCA', 'CCA', 'RDA', 'NMDS', 'MDS', 'PCoA')), type (The plot type. Default is 'samples'. The currently supported options are c('samples', 'taxa', 'biplot', 'split', 'scree')), group (The name of the variable to map to colors in the plot), shape (The name of the variable to map to different shapes on the plot), label (The name of the variable to map to text labels on the plot). Expected Output: An ordination object (res_ord$ordination) and figure plot (res_ord$fig_ord). Tools Used: cal_ordination function.Step9: cal_marker function: Description: This function is only a wrapper of all differential analysis functions, We recommend to use the corresponding function, since it has a better default arguments setting. Parameters: ps (phyloseq object), group (A string indicating the variable for group identifiers), da_method (character to specify the differential analysis method. The options include:c('lefse','simple_t','simple_welch','simple_white','simple_kruskal','simple_anova','edger','deseq2','metagenomeseq','ancom','ancombc','aldex','limma_voom','sl_lr','sl_rf','sl_svm')), tax_rank (character to specify taxonomic rank to perform differential analysis on), transform (the methods used to transform the microbial abundance, default is identity), norm (the methods used to normalize the microbial abundance data), norm_para (arguments passed to specific normalization methods), p_adjust (method for multiple test correction, default none), pvalue_cutoff (p value cutoff, default 0.05). Expected Output: a microbiomeMarker table (mm@marker_table), in which the slot of marker_table contains four variables (feature, enrich_group, lda, pvalue), `microbiomeMarker::plot_ef_bar(mm)` plot bar of markers, `microbiomeMarker::plot_abundance(mm,group = iGroup)` plot abundance of markers. Tools Used: R packages microbiomeMarker, run_lefse function.",
        "metadata": {
            "source": "R",
            "page": 3
        }
    },
    {
        "content": "admixtools is an R package, and once installed, you can begin using it by entering the R environment and running the relevant commands. When using it, create another /admixtools/ folder under the target output path and put all the output into it. You can enter the R environment by entering an R as a line in the command line also can use Rscript. not install any package. If you don't have the admixtools package, check case and try library(admixtools) ,library(tidyverse) is imported as follows.f2 in ADMIXTOOLS 2\nIn ADMIXTOOLS 2, f2-statistics are the foundation for all further analyses. They can be computed from genotype data and saved to disk with this command:\n\nprefix = '/path/to/geno'\nmy_f2_dir = '/store/f2data/here/'\n\nextract_f2(prefix, my_f2_dir)\nThis will look for genotype files in packedancestrymap or PLINK format, compute allele frequencies and blocked f4-statistics for all pairs of populations defined in the .ind or .fam file, and write them to my_f2_dir. It is also possible to extract only a subset of the samples or populations by passing IDs to the inds and pops arguments in extract_f2(). To get a description of the arguments and to see examples of how to use it, type\n\n?extract_f2\nBy default, extract_f2() will be very cautious and exclude all SNPs which are missing in any population (maxmiss = 0). If you lose too many SNPs this way, you can either\n\nlimit the number of populations for which to extract f2-statistics,\ncompute f3- and f4-statistics directly from genotype files, or\nincrease the maxmiss parameter (maxmiss = 1 means no SNPs will be excluded).\nThe advantages and disadvantages of the different approaches are described here. Briefly, when running qpadm() and qpdstat() it can be better to choose the safer but slower options 1 and 2, while for qpgraph(), which is not centered around hypothesis testing, it is usually fine choose option 3. Since the absolute difference in f-statistics between these approaches is usually small, it can also make sense to use option 3 for exploratory analyses, and confirm key results using options 1 or 2.\n\nOnce extract_f2() has finished, f2-statistics for the populations of interest can be loaded using f2_from_precomp():\n\nf2_blocks = f2_from_precomp(my_f2_dir)\nOr you can load only a subset of the populations:\n\nmypops = c('Denisova.DG', 'Altai_Neanderthal.DG', 'Vindija.DG')\nf2_blocks = f2_from_precomp(my_f2_dir, pops = mypops)\nIf your data is so small that computing f2-statistics doesn’t take very long, you can skip writing the data to disk with extract_f2() and do everything in one step using f2_from_geno():\n\nf2_blocks = f2_from_geno(my_f2_dir, pops = mypops)\nf2_blocks is now a 3d-array with f2-statistics for each population pair along dimensions 1 and 2, and each SNP block along the 3rd dimension.\n\ndim(f2_blocks)\n## [1]   7   7 708\nThe purpose of having separate estimates for each SNP block is to compute jackknife or bootstrap standard errors for f-statistics, and for any statistics derived from them.\n\nf2_blocks can be used like this:\n\nf2_blocks[,,1]                # f2-statistics of the 1st SNP block\napply(f2_blocks, 1:2, mean)   # average across all blocks\nf2_blocks[pop1, pop2, ]       # f2(pop1, pop2) for all blocks\nThe names along the 3rd dimension contain the SNP block lengths:\n\nblock_lengths = parse_number(dimnames(f2_blocks)[[3]])\nhead(block_lengths)\n## [1] 424 772 795 835 574 842\nTo see the total number of SNPs across all blocks, you can use count_snps()\n\ncount_snps(f2_blocks)\n## [1] 780009\nIf you want to try any of this without extracting and loading your own f2-statistics, you can instead use example_f2_blocks which becomes available after running library(admixtools).\n\n\nMore information on f-statistics in ADMIXTOOLS 2\n\n\n\nf3 and qp3Pop\nThere are three main uses of f3-statistics:\n\nTesting whether a population is admixed: If f3(A;B,C) is negative, this suggests that A is admixed between a population related to B and one related to C.\nEstimating the relative divergence time for pairs of populations (outgroup f3-statistics): Pairwise FST and f2 are simpler estimates of genetic distance or divergence time, but they are affected by differences in population size. If O is an outgroup relative to all populations i and j, then f3(O;i,j) will estimate the genetic distance between O and the points of separation between i and j without being affected by drift that is specific to any population i or j.\nFitting admixture graphs: f3-statistics of the form f3(O;i,j) for an arbitrary population O, and all pairs of i and j are used in qpGraph, which is described below.\nThe original ADMIXTOOLS program for computing f3-statistics is called qp3Pop. In ADMIXTOOLS 2, you can compute f3-statistics like this:\n\npop1 = 'Denisova.DG'\npop2 = c('Altai_Neanderthal.DG', 'Vindija.DG')\npop3 = c('Chimp.REF', 'Mbuti.DG', 'Russia_Ust_Ishim.DG')\nqp3pop(f2_blocks, pop1, pop2, pop3)\nOr, equivalently\n\nf3(f2_blocks, pop1, pop2, pop3)\n## # A tibble: 6 × 7\n##   pop1        pop2                 pop3                  est      se     z     p\n##   <chr>       <chr>                <chr>               <dbl>   <dbl> <dbl> <dbl>\n## 1 Denisova.DG Altai_Neanderthal.DG Chimp.REF          0.0591 5.98e-4  98.7     0\n## 2 Denisova.DG Altai_Neanderthal.DG Mbuti.DG           0.0720 6.47e-4 111.      0\n## 3 Denisova.DG Altai_Neanderthal.DG Russia_Ust_Ishim.… 0.0742 7.02e-4 106.      0\n## 4 Denisova.DG Vindija.DG           Chimp.REF          0.0594 5.92e-4 100.      0\n## 5 Denisova.DG Vindija.DG           Mbuti.DG           0.0724 6.34e-4 114.      0\n## 6 Denisova.DG Vindija.DG           Russia_Ust_Ishim.… 0.0750 6.96e-4 108.      0\nThis will compute f3-statistics for all combinations of pop1, pop2, and pop3. f3(f2_blocks) will compute all possible combinations (which can be a large number). If only pop1 is supplied, all combinations of populations in pop1 will be computed.\n\n\nf4 and qpDstat\nThe original ADMIXTOOLS program for computing f4-statistics is called qpDstat. As the name suggests, it computes D-statistics by default. To get f4-statistics instead, the f4mode argument needs to set to YES. In ADMIXTOOLS 2, almost everything starts with f2-statistics, so the qpdstat/f4 function computes f4-statistics by default.\n\npop4 = 'Switzerland_Bichon.SG'\nf4(f2_blocks, pop1, pop2, pop3, pop4)\nqpdstat(f2_blocks, pop1, pop2, pop3, pop4)\n# two names for the same function\n## # A tibble: 6 × 8\n##   pop1        pop2                 pop3  pop4       est      se      z         p\n##   <chr>       <chr>                <chr> <chr>    <dbl>   <dbl>  <dbl>     <dbl>\n## 1 Denisova.DG Altai_Neanderthal.DG Chim… Swit…  1.50e-2 4.64e-4 32.3   6.06e-229\n## 2 Denisova.DG Altai_Neanderthal.DG Mbut… Swit…  2.03e-3 3.53e-4  5.75  8.85e-  9\n## 3 Denisova.DG Altai_Neanderthal.DG Russ… Swit… -2.17e-4 3.73e-4 -0.580 5.62e-  1\n## 4 Denisova.DG Vindija.DG           Chim… Swit…  1.54e-2 4.78e-4 32.2   5.81e-228\n## 5 Denisova.DG Vindija.DG           Mbut… Swit…  2.33e-3 3.63e-4  6.42  1.40e- 10\n## 6 Denisova.DG Vindija.DG           Russ… Swit… -2.40e-4 3.87e-4 -0.620 5.35e-  1\nThe differences between f4-statistics and D-statistics are usually negligible. However, it is still possible to compute D-statistics in ADMIXTOOLS 2, by providing genotype data as the first argument, and setting f4mode = FALSE:\n\nprefix = '/path/to/geno'\nf4(prefix, pop1, pop2, pop3, pop4, f4mode = FALSE)\nComputing f4- or D-statistics from genotype data directly is slower, but it has the advantage that it avoids any problems that may arise from large amounts of missing data. More on this here.\n\n\n\nFST\nFST is closely related to f2, but unlike f2, it doesn’t function as a building block for other tools in ADMIXTOOLS 2. However, it is the most widely used metric to estimate the genetic distance between populations. Running extract_f2() will create files which don’t only contain f2 estimates for each population pair, but also separate FST estimates. The function fst() can either read these pre-computed estimates, or compute them directly from genotype files:\n\nfst(my_f2_dir)\nfst(prefix, pop1 = \"Altai_Neanderthal.DG\", pop2 = c(\"Denisova.DG\", \"Vindija.DG\"))\nTo estimate FST without bias, we need at least two independent observations in each population. With pseudohaploid data, we only get one independent observation per sample, and so for populations consisting of only one pseudohaploid sample, FST cannot be estimated without bias. If we want to ignore that bias and get estimates anyway, we can pretend the pseudohaploid samples are actually diploid using the option adjust_pseudohaploid = FALSE.\n\nfst(prefix, pop1 = \"Altai_Neanderthal.DG\", pop2 = c(\"Denisova.DG\", \"Vindija.DG\"),\n    adjust_pseudohaploid = FALSE)\n\n\nqpWave and qpAdm\nqpWave and qpAdm are two programs with different goals - qpWave is used for estimating the number of admixture events, and qpAdm is used for estimating admixture weights - but they perform almost the same computations. The key difference is that qpWave compares two sets of populations (left and right), while qpAdm tests how a single target population (which can be one of the left populations) relates to left and right. In ADMIXTOOLS 2, both qpadm() and qpwave() require at least three arguments:\n\nf2-statistics\nA set of left populations\nA set of right populations\nqpadm() additionally requires a target population as the 4th argument, which will be modeled as a mixture of left populations.\n\nleft = c('Altai_Neanderthal.DG', 'Vindija.DG')\nright = c('Chimp.REF', 'Mbuti.DG', 'Russia_Ust_Ishim.DG', 'Switzerland_Bichon.SG')\ntarget = 'Denisova.DG'\npops = c(left, right, target)\nBoth functions will return f4-statistics, and a data frame that shows how well the f4-matrix can be approximated by lower rank matrices. The last line tests for rank 0, which is equivalent to testing whether the left populations form a clade with respect to the right populations.\n\nresults = qpwave(f2_blocks, left, right)\nresults$f4\n## # A tibble: 3 × 8\n##   pop1                 pop2       pop3      pop4       est      se     z       p\n##   <chr>                <chr>      <chr>     <chr>    <dbl>   <dbl> <dbl>   <dbl>\n## 1 Altai_Neanderthal.DG Vindija.DG Chimp.REF Mbuti… 1.24e-4 1.35e-4 0.920 0.358  \n## 2 Altai_Neanderthal.DG Vindija.DG Chimp.REF Russi… 4.45e-4 1.64e-4 2.72  0.00653\n## 3 Altai_Neanderthal.DG Vindija.DG Chimp.REF Switz… 4.22e-4 1.72e-4 2.45  0.0144\nresults$rankdrop\n## # A tibble: 1 × 7\n##   f4rank   dof chisq       p dofdiff chisqdiff p_nested\n##    <int> <int> <dbl>   <dbl>   <int>     <dbl>    <dbl>\n## 1      0     3  11.9 0.00768      NA        NA       NA\nqpadm() will also compute admixture weights and nested models:\n\nweights: These are the admixture weights, or estimates of the relative contributions of the left population to the target population.\npopdrop: popdrop shows the fits of all models generated by dropping a specific subset of left populations, and will only be returned if a target population is specified.\nf4: The estimated f4-statistics will now also include lines with fitted f4-statistics, where the target population is in the first column, and a weighted sum of the left populations, fit, in the second column.\nresults = qpadm(f2_blocks, left, right, target)\nresults$weights\n## # A tibble: 2 × 5\n##   target      left                 weight    se     z\n##   <chr>       <chr>                 <dbl> <dbl> <dbl>\n## 1 Denisova.DG Altai_Neanderthal.DG   49.6  23.3  2.13\n## 2 Denisova.DG Vindija.DG            -48.6  23.3 -2.08\nresults$popdrop\n## # A tibble: 3 × 13\n##   pat      wt   dof    chisq      p f4rank Altai_Neanderthal.DG Vindija.DG\n##   <chr> <dbl> <dbl>    <dbl>  <dbl>  <dbl>                <dbl>      <dbl>\n## 1 00        0     2     7.15 0.0280      1                 49.6      -48.6\n## 2 01        1     3 11412.   0           0                  1         NA  \n## 3 10        1     3 11449.   0           0                 NA          1  \n## # ℹ 5 more variables: feasible <lgl>, best <lgl>, dofdiff <dbl>,\n## #   chisqdiff <dbl>, p_nested <dbl>\n\n\nRunning many models\nThere are several functions that can be used to run many qpWave or qpAdm models at the same time.\n\nPairwise cladality tests\nqpwave_pairs() forms all pairs of left populations and tests whether they form a clade with respect to the right populations.\n\nqpwave_pairs(f2_blocks, left = c(target, left), right = right)\n## # A tibble: 6 × 4\n##   pop1                 pop2                  chisq       p\n##   <chr>                <chr>                 <dbl>   <dbl>\n## 1 Altai_Neanderthal.DG Denisova.DG          1507.  0      \n## 2 Altai_Neanderthal.DG Vindija.DG             11.9 0.00768\n## 3 Denisova.DG          Altai_Neanderthal.DG 1507.  0      \n## 4 Denisova.DG          Vindija.DG           1510.  0      \n## 5 Vindija.DG           Altai_Neanderthal.DG   11.9 0.00768\n## 6 Vindija.DG           Denisova.DG          1510.  0\nRotating outgroups\nqpadm_rotate() tests many qpadm() models at a time. For each model, the leftright populations will be split into two groups: The first group will be the left populations passed to qpadm(), while the second group will be added to rightfix and become the set of right populations. By default, this function will only compute p-values but not weights for each model (which makes it faster). If you want the full output for each model, set full_results = TRUE.\n\nqpadm_rotate(f2_blocks, leftright = pops[3:7], target = pops[1], rightfix = pops[1:2])\n## ℹ Evaluating 25 models...\n## \n## # A tibble: 25 × 7\n##    left      right     f4rank   dof   chisq        p feasible\n##    <list>    <list>     <dbl> <dbl>   <dbl>    <dbl> <lgl>   \n##  1 <chr [1]> <chr [6]>      0     5 26194.  0        TRUE    \n##  2 <chr [1]> <chr [6]>      0     5 53965.  0        TRUE    \n##  3 <chr [1]> <chr [6]>      0     5 43564.  0        TRUE    \n##  4 <chr [1]> <chr [6]>      0     5 54909.  0        TRUE    \n##  5 <chr [1]> <chr [6]>      0     5 13167.  0        TRUE    \n##  6 <chr [2]> <chr [5]>      1     3 10602.  0        FALSE   \n##  7 <chr [2]> <chr [5]>      1     3 13506.  0        FALSE   \n##  8 <chr [2]> <chr [5]>      1     3 13447.  0        FALSE   \n##  9 <chr [2]> <chr [5]>      1     3    72.2 1.46e-15 FALSE   \n## 10 <chr [2]> <chr [5]>      1     3  4030.  0        FALSE   \n## # ℹ 15 more rows\nMany qpadm models\nSwapping some populations between the left and the right set is one common way to run multiple qpadm() models. There is also a more general function, in which you can specify any models that you want to run. This is faster than looping over several calls to the qpadm() function, in particular when reading data from a genotype matrix directly, because it re-uses f4-statistics.\n\nTo specify the qpadm() models you want to run, you need to make a data frame with columns left, right, and target, where each model is in a different row.\n\nmodels = tibble(\n           left = list(pops[1:2], pops[3]),\n           right = list(pops[4:6], pops[1:2]),\n           target = c(pops[7], pops[7]))\nresults = qpadm_multi('/my/geno/prefix', models)\n## ℹ Running models...\n## \nThe output is a list where each item is the result from one model. The following command would combine the weights for all models into a new data frame:\n\nresults %>% map('weights') %>% bind_rows(.id = 'model')\n## # A tibble: 3 × 6\n##   model target      left                 weight       se        z\n##   <chr> <chr>       <chr>                 <dbl>    <dbl>    <dbl>\n## 1 1     Denisova.DG Altai_Neanderthal.DG   7.92 2.44e+ 0  3.25e 0\n## 2 1     Denisova.DG Vindija.DG            -6.92 2.44e+ 0 -2.84e 0\n## 3 2     Denisova.DG Chimp.REF              1    1.78e-13  5.63e12\n\n\nqpGraph\nSingle f3-and f4-statistics can tell us how three or four populations are related to each other. qpGraph generalizes this concept to any number of populations. It takes estimated f3-statistics and the topology of an admixture graph, finds the edges weights that minimize the difference between fitted and estimated f3-statistics, and summarizes that difference in a likelihood score. A good model should fit all f3-statistics, and have a score close to zero.\n\nqpg_results = qpgraph(f2_blocks, example_graph)\nqpg_results$score\n## [1] 19219.98\nHere, example_graph is a specific graph included in this R package, but you can provide any other graph in one of three formats.\n\nAn igraph object.\nA two column matrix or data frame, where each row is an edge, the first column is the source of the edge, and the second column is the target. Additional columns labelled lower and upper can be used to constrain certain edges (NA = no constraint).\nThe location of a qpGraph graph file, which will be read and parsed.\nThe leaf nodes of this graph have to match the f2-statistic population labels, and the graph has to be a valid admixture graph: a directed acyclic graph where each node has no more than two parents. If nodes with more than two children are present (polytomies or multifurcations) they will be split in a random order, and the new drift edges will be constrained to 0.\n\n\n\nThe output of qpgraph() is a list with several items:\n\nedges: A data frame with estimated edge weights. This includes normal edges as well as admixture edges.\nscore: The likelihood score. Smaller scores indicate a better fit.\nf2: Estimated f2-statistics and standard errors for all population pairs.\nf3: Estimated and fitted f3-statistics for all population pairs with the outgroup. This includes residuals and z-scores.\nopt: A data frame with details from the weight optimization, with one row per set of starting values.\nppinv: The inverse of the f3-statistics covariance matrix.\nOptionally, fitted and estimated f4-statistics are returned as f4 and the worst residual z-score as worst_residual if return_fstats is set to TRUE. When f2_blocks_test is provided, an out-of-sample score is computed and returned as score_test.\n\nThe fitted graph can be plotted like this:\n\nplot_graph(qpg_results$edges)\n\n\nor as an interactive plot if you want to know the names of the inner nodes:\n\nplotly_graph(qpg_results$edges)\n",
        "metadata": {
            "source": "admixtools",
            "page": 3
        }
        
    },
    {
        "content": "For performing Treemix analysis with PLINK files (.bed, .bim, .fam), follow the steps below.All sample scripts such as plink2treemix.py and vcf2treemix.sh are in the current directory, i.e./plink2treemix.py and./vcf2treemix.sh. Simply modify the input and output file paths as necessary:\n\n1. Convert PLINK files to VCF format:\n   ```plink --bfile ./data/1000GP_pruned --recode vcf --out ./output/094/1000GP_pruned```\n   This command converts the PLINK files (`.bed`, `.bim`, `.fam`) into a VCF file (`1000GP_pruned.vcf`).\n\n2. Compress the VCF file using bgzip:\n   ```bgzip ./output/094/1000GP_pruned.vcf```\n   Compresses the VCF file to `.vcf.gz` format using `bgzip`.\n\n3. Remove variants with missing data using vcftools:\n   ```vcftools --gzvcf ./output/094/1000GP_pruned.vcf.gz --max-missing 1 --recode --stdout | gzip > ./output/094/1000GP_pruned_no_missing.vcf.gz```\n   Filters out variants with missing genotypes and generates a new compressed VCF file (`1000GP_pruned_no_missing.vcf.gz`).\n\n4. Perform LD pruning using PLINK:\n   ```plink --vcf ./output/094/1000GP_pruned_no_missing.vcf.gz --indep-pairwise 50 5 0.2 --out ./output/094/1000GP_pruned_no_missing_LDpruned```\n   Performs LD pruning to remove variants in high linkage disequilibrium based on the parameters (window size 50 SNPs, step size 5, r^2 threshold 0.2).\n\n5. Create a new VCF with LD-pruned SNPs:\n   ```plink --vcf ./output/094/1000GP_pruned_no_missing.vcf.gz --extract ./output/094/1000GP_pruned_no_missing_LDpruned.prune.in --recode vcf --out ./output/094/1000GP_pruned_LDpruned```\n   Generates a new VCF file (`1000GP_pruned_LDpruned.vcf`) containing only the pruned SNPs.\n\n6. Compress the LD-pruned VCF file using bgzip:\n   ```bgzip ./output/094/1000GP_pruned_LDpruned.vcf```\n   Compresses the LD-pruned VCF file to `.vcf.gz`.\n\n7. Generate a cluster file for Treemix:\n   ```bcftools query -l ./output/094/1000GP_pruned_LDpruned.vcf.gz | awk 'BEGIN{OFS=\"\\t\"} {split($1,pop,\"_\"); print $1, $1, pop[1]}' > ./output/094/1000GP_pruned_LDpruned.clust```\n   Creates a cluster file for Treemix, where the population is determined by the prefix of the sample ID.\n\n8. Run the `vcf2treemix.sh` script to prepare data for Treemix:\n   ```bash vcf2treemix.sh ./output/094/1000GP_pruned_LDpruned.vcf.gz  ./output/094/1000GP_pruned_LDpruned.clust```\n   Converts the VCF and cluster files into the format required for Treemix analysis.\n\n9. Run Treemix with different migration models:\n   ```\n   for i in {0..5}\n   do\n   treemix -i ./output/094/1000GP_pruned_LDpruned.treemix.frq.gz -m $i -o ./output/094/1000GP_no_missing_result -root GBR -bootstrap -k 500 -noss > treemix_${i}_log &\n   done\n   ```\n   Runs Treemix with migration models ranging from 0 to 5, and saves the results in the specified output directory. The loop also generates log files for each model (e.g., `treemix_0_log`, `treemix_1_log`, etc.).",
        "metadata": {
            "source": "Treemix",
            "page": 3
        }
        
    },
    {
        "content": "You can enter R in a single line or use Rscript to enter the R environment, admixtool and other packages have been installed, no additional installation is required. ### D Statistic (D-test) Explanation\n\n**D Statistic**, also known as the BABA-ABBA test, detects gene flow or admixture between populations by comparing allele patterns across four groups.\n\n#### Key Concepts\n- **PopA & PopB**: Main populations being compared.\n- **PopC**: Reference population (outgroup).\n- **PopD**: Test population for potential gene flow.\n\n#### BABA-ABBA Patterns\n- **BABA**: PopA has a specific allele; PopB does not.\n- **ABBA**: PopB has a specific allele; PopA does not.\n\nComparing these patterns reveals gene flow direction and strength.\n\n#### Analysis Steps\n1. **Data Preparation**: Use PLINK to preprocess genotype data.\n2. **Define Populations**: Select PopA, PopB, PopC, and PopD.\n3. **Calculate D Statistic**: Use the `f4` function from the `admixtools` package.\n4. **Interpret Results**:\n   - **D ≠ 0**: Indicates gene flow.\n   - **Positive/Negative**: Direction of gene flow.\n\n#### Code Overview\n```r\nlibrary(admixtools)\noutput_dir <- \"./output/090\"\nprefix <- \"./data/1000GP_pruned\"\n\nfam_data <- read.table(paste0(prefix, \".fam\"), header = FALSE)\ncolnames(fam_data) <- c(\"Population\", \"SampleID\", \"FatherID\", \"MotherID\", \"Sex\", \"Phenotype\")\ntable(fam_data$Population)\n\npopA <- 'CEU'\npopB <- 'GBR'\npopC <- 'YRI'\npopD <- 'ESN'\n\nD_results <- f4(prefix, popA, popB, popC, popD, f4mode = FALSE)\nwrite.table(D_results, file.path(output_dir, \"D_test_results.txt\"), sep = \"\\t\", row.names = FALSE, col.names = TRUE)\nprint(D_results)\n```\n\n- **Loading Package**: `admixtools` for admixture analysis.\n- **Setting Paths**: Define input and output directories.\n- **Data Handling**: Read and label population data.\n- **Define Populations**: Specify the four populations.\n- **Compute D Statistic**: Perform the BABA-ABBA test.\n- **Output Results**: Save and display the results.\n\n#### Result Interpretation\n- **D Value**: Significant deviation from zero indicates gene flow.\n- **Sign**: Positive or negative values show the direction of gene flow.\n\nThe D statistic helps understand historical gene flow and population relationships.",
        "metadata": {
            "source": "Admixtools(D)",
            "page": 3
        }
        
    },
    {
        "content": "2. run-sort-bam.sh:\nData-type-independent, generic bam sorting module\nInput : any unsorted bam file (.bam)\nOutput : a bam file sorted by coordinate (.sorted.bam) and its index (.sorted.bam.bai).\nUsage\nRun the following in the container.\nrun-sort-bam.sh <input_bam> <output_prefix>\n# input_bam : any bam file to be sorted\n# output_prefix : prefix of the output bam file.\n\nSet parameters according to the example: Suppose the input file is: ./output/GM12878_bwa_1.bam and ./output/GM12878_bwa_2.bam, the target is./output/GM12878_bwa_sorted.bam and ./output/GM12878_bwa_sorted, Generate the following sample script:\nbash ./scripts/run-sort-bam.sh ./output/GM12878_bwa_1.bam ./output/GM12878_bwa_sorted \n\nbash ./scripts/run-sort-bam.sh ./output/GM12878_bwa_2.bam ./output/GM12878_bwa_sorted\n\nYou can install the tool, but do not do any additional operations.You can install the tool, but do not do any additional operations.Please follow the example to generate rather than copy and paste completely, especially for folder names, file names, etc.",
        "metadata": {
            "source": "run-sort-bam.sh",
            "page": 3
        }
        
    },
    {
        "content": "3. run-bam2pairs.sh:\nBam to pairs conversion module for Hi-C data, based on samtools, bgzip and pairix.\nInput : any paired-end bam file\nOutput : a chromosome-block-sorted and bgzipped pairs pairs file that contains all the mapped read pairs in the bam file, along with its index (.bsorted.pairs.gz and .bsorted.pairs.gz.px2)\nUsage\nRun the following in the container.\nrun-bam2pairs.sh <input_bam> <output_prefix>\n# input_bam : input bam file.\n# output_prefix : prefix of the output pairs file.\nSet parameters according to the example:\nSuppose the input file is: ./output/GM12878_bwa_sorted_1.bam and ./output/GM12878_bwa_sorted_2.bam, the target is./output/GM12878_bwa_sorted_pairs  and./output/GM12878_bwa_sorted_pairs , Generate the following sample script:\nbash ./scripts/run-bam2pairs.sh ./output/GM12878_bwa_sorted_1.bam ./output/GM12878_bwa_sorted_pairs   \nbash ./scripts/run-bam2pairs.sh ./output/GM12878_bwa_sorted_2.bam ./output/GM12878_bwa_sorted_pairs \n\nYou can install the tool, but do not do any additional operations.You can install the tool, but do not do any additional operations.Please follow the example to generate rather than copy and paste completely, especially for folder names, file names, etc.",
        "metadata": {
            "source": "run-bam2pairs.sh",
            "page": 3
        }
        
    },
    {
        "content": "1. run-bwa-mem.sh:\nAlignment module for Hi-C data, based on bwa-mem.\nInput : a pair of Hi-C fastq files\nOutput : a bam file (Lossless, not sorted by coordinate)\nUsage\nRun the following in the container.\nrun-bwa-mem.sh <fastq1> <fastq2> <bwaIndex> <outdir> <output_prefix> <nThreads>\n# fastq1, fastq2 : input fastq files, either gzipped or not\n# bwaIndex : tarball for bwa index, .tgz.\n# outdir : output directory\n# output_prefix : prefix of the output bam file.\n# nThreads : number of threads\n\nThe script is invoked in the./script/ path as bash./script/run-bwa-mem.sh. Set parameters according to the example:I want to output under./output/003/.Reference file path for: ./data/hg38.bwaindex.tgz,no need to extract the reference file, and the first pair are ./data/4DNFI15H1RVG.fastq.gz and ./data/4DNFIZHUKESO.fastq.gz, the second pair are for: ./data/4DNFIKVDGNJN.fastq.gz and ./data/4DNFIEQ58J6G.fastq.gz,  the target is the first pair result is ./ouput/003/bwa_1.bam,the second pair result is./output/003/bwa.2.bam. the generated script is:\n\nbash ./scripts/run-bwa-mem.sh ./data/4DNFI15H1RVG.fastq.gz ./data/4DNFIZHUKESO.fastq.gz  ./data/hg38.bwaindex.tgz ./output/003/  bwa_1 64\n\nbash ./scripts/run-bwa-mem.sh ./data/4DNFIKVDGNJN.fastq.gz ./data/4DNFIEQ58J6G.fastq.gz  ./data/hg38.bwaindex.tgz ./output/003/   bwa_2 64\n\nWhen the command is generated, the file name and the output path must require a space, otherwise the file name will be regarded as the folder name. bwa_1,bwa_2 indicate the generated file name, You should adjust according to the description of the desired destination file name. and 64 indicate the number of threads. The number of threads is usually set to 16 or 32. You can install the tool, but do not do any additional operations.Please follow the example to generate rather than copy and paste completely, especially for folder names, file names, etc.",
        "metadata": {
            "source": "run-bwa-mem.sh",
            "page": 3
        }
    },
    {
        "content": "2. run-pairsam-parse-sort.sh\nRuns pairsam parse and sort on a bwa-produced bam file and produces a sorted pairsam file\nInput: a bam file\nOutput: a pairsam file\nUsage\nRun the following in the container\nrun-pairsam-parse-sort.sh <input_bam> <chromsizes> <outdir> <outprefix> <nthread> <compress_program>\n# input_bam : an input bam file.\n# chromsizes : a chromsize file\n# outdir : output directory\n# outprefix : prefix of output files\n# nthread : number of threads to use\n\nSet parameters according to the example:\nSuppose the input file is: ./output/aligned/a1.bam  and ./output/aligned/abc.bam, the target is ./output/003/pairsam_fix1.sam.pairs.gz and ./output/003/pairsam_fix2.sam.pairs.gz . ./hg38.chrom.sizes  is the a chromsize file. Generate the following sample script:\n\nbash ./scripts/run-pairsam-parse-sort.sh ./output/aligned/a1.bam ./hg38.chrom.sizes ./output/003/  pairsam_fix1 64 lz4c \nbash ./scripts/run-pairsam-parse-sort.sh ./output/aligned/abc.bam ./hg38.chrom.sizes ./output/003/  pairsam_fix2 64 lz4c\n\nYou can install the tool, but do not do any additional operations.and 64 indicate the number of threads.Please follow the example to generate rather than copy and paste completely, especially for folder names, file names, etc.",        "metadata": {
            "source": "run-pairsam-parse-sort.sh",
            "page": 3
        }
        
    },
    {
        "content": "3. run-pairsam-merge.sh\nMerges a list of pairsam files\nInput: a list of pairsam files\nOutput: a merged pairsam file\nUsage\nRun the following in the container\nrun-pairsam-merge.sh <outprefix> <nthreads> <input_pairsam1> [<input_pairsam2> [<input_pairsam3> [...]]]\n# outprefix : prefix of output files\n# nthreads : number of threads to use   \n# input_pairsam : an input pairsam file.\n\nSet parameters according to the example:\nSuppose the input file is: ./output/003/pairsam_fix1.sam.pairs.gz  and ./output/003/pairsam_fix2.sam.pairs.gz, the target is ./output/003/out.merged.sam.pairs.gz . Generate the following sample script:\n\nbash ./scripts/run-pairsam-merge.sh ./output/003/out 64 './output/003/pairsam_fix1.sam.pairs.gz ./output/003/pairsam_fix2.sam.pairs.gz' \n\nYou can install the tool, but do not do any additional operations.Please follow the example to generate rather than copy and paste completely, especially for folder names, file names, etc.and 64 indicate the number of threads.",            "metadata": {
            "source": "run-pairsam-parse-sort.sh",
            "page": 3
        }
        
    },
    {
        "content": "4. run-pairsam-markasdup.sh\nTakes a pairsam file in and creates a pairsam file with duplicate reads marked\n* Input: a pairsam file\n* Output: a duplicate-marked pairsam file\nUsage\nRun the following in the container\nrun-pairsam-markasdup.sh <input_pairsam>\n# input_pairsam : an input pairsam file.\n# outprefix : prefix of output files\n\nSet parameters according to the example:\nSuppose the input file is:  ./output/003/out.merged.sam.pairs.gz,the target is ./output/003/out1.  Generate the following sample script:\n\nbash ./scripts/run-pairsam-markasdup.sh  ./output/003/out.merged.sam.pairs.gz  ./output/003/out1  \n\nYou can install the tool, but do not do any additional operations.Please follow the example to generate rather than copy and paste completely, especially for folder names, file names, etc.and 64 indicate the number of threads.",          
        "metadata": 
        {            
            "source": "run-pairsam-parse-sort.sh",
            "page": 3
        }
        
    },
    {
        "content": "5. run-pairsam-filter.sh\nTakes in a pairsam file and creates a lossless, annotated bam file and a filtered pairs file.\nInput: a pairsam file\nOutput: an annotated bam file and a filtered pairs file\nUsage\nRun the following in the container\nrun-pairsam-filter.sh <input_pairsam> <outprefix> <chromsizes>\n# input_pairsam : an input pairsam file.\n# outprefix : prefix of output files\n# chromsizes : a chromsize file\n\nSet parameters according to the example:\nSuppose the input file is: ../sample_data/outlala.merged.sam.pairs.gz, the target is  ./out/out12345.dedup.pairs.gz and ./out/out12345.lossless.bam ,/home/agent/POPGENAGENT/data/hg38.chrom.sizes is the a chromsize file. Generate the following sample script:\n\nbash ./scripts/run-pairsam-filter.sh  ./sample_data/outlala.merged.sam.pairs.gz ./out/out12345  /home/agent/POPGENAGENT/data/hg38.chrom.sizes\n\nYou can install the tool, but do not do any additional operations.Please follow the example to generate rather than copy and paste completely, especially for folder names, file names, etc.",            "metadata": {
            "source": "run-pairsam-parse-sort.sh",
            "page": 3
        }
        
    },
    {
        "content": "6. run-merge-pairs.sh\nAlignment module for Hi-C data, based on merge-pairs.\n\nInput : a set of pairs files, with their associated indices\nOutput : a merged pairs file and its index\nUsage\nRun the following in the container.\nrun-merge-pairs.sh <output_prefix> <pairs1> <pairs2> [<pairs3> [...]]  \n# output_prefix : prefix of the output pairs file.\n# pairs1, pairs2, ... : input pairs files\n\nSet parameters according to the example:\nSuppose the input file is: ./out/out12345.dedup.pairs.gz, the target is ./out/out321.pairs.gz. Generate the following sample script:\n\nbash ./scripts/run-merge-pairs.sh ./out/out321 ./out/out12345.dedup.pairs.gz\n\nYou can install the tool, but do not do any additional operations. Please follow the example to generate rather than copy and paste completely, especially for folder names, file names, etc.",
            "metadata": {
            "source": "run-pairsam-parse-sort.sh",
            "page": 3
        }
        
    },
    {
        "content": "7. run-cooler.sh\nRuns cooler to create an unnormalized matrix .cool file, taking in a (4dn-style) pairs file\nInput : a pairs file (.gz, along with .px2), chrom.size file\nOutput : a contact matrix file (.cool)\nUsage\nRun the following in the container.\nrun-cooler.sh <input_pairs> `<chromsize>` `<binsize>` `<ncores>` <output_prefix> <max_split>\nrun-cooler.sh <input_pairs> <chromsize> <binsize> <ncores> <output_prefix> <max_split>\n# input_pairs : a pairs file\n# chromsize : a chromsize file\n# binsize : binsize in bp\n# ncores : number of cores to use\n# output_prefix : prefix of the output cool file\n# max_split : max_split argument for cooler (e.g. 2 which is default for cooler) \n\nSet parameters according to the example:\nSuppose the input file is:/home/agent/POPGENAGENT/sample_data/outlala.ff.pairs.gz , the target is  ./out/out3 ,/home/agent/POPGENAGENT/data/hg38.chrom.sizes is the a chromsize file. Generate the following sample script:\n\nbash ./scripts/run-cooler.sh      /home/agent/POPGENAGENT/sample_data/outlala.ff.pairs.gz      /home/agent/POPGENAGENT/data/hg38.chrom.sizes      1000      32      ./out/out3      2\n\nYou can install the tool, but do not do any additional operations.Please follow the example to generate rather than copy and paste completely, especially for folder names, file names, etc.and 32 indicate the number of threads.",            "metadata": {
            "source": "run-pairsam-parse-sort.sh",
            "page": 3
        }
        
    },
    {
        "content": "8. run-cooler-balance.sh\nRuns cooler to create a normalized matrix file, taking in an unnormalized .cool file\nInput: a cool file (.cool)\nOutput : a cool file (.cool)\nUsage\nRun the following in the container.\nrun-cooler-balance.sh <input_cool> <max_iter> <output_prefix> <chunksize>\n# input_cool : a cool file (without normalization vector)\n# max_iter : maximum number of iterations\n# output_prefix : prefix of the output cool file\n# chunksize : chunksize argument for cooler (e.g. 10000000 which is default for cooler)\n\nSet parameters according to the example:\nSuppose the input file is: ./output/003/cool_prefix.cool , the target is ./output/003/cool_prefix_normalized.cool,/home/agent/POPGENAGENT/data/hg38.chrom.sizes is the a chromsize file. Generate the following sample script:\n\nbash ./scripts/run-cooler-balance.sh ./output/003/cool_prefix.cool 1000 ./output/003/cool_prefix_normalized 10000000\n\nYou can install the tool, but do not do any additional operations.Please follow the example to generate rather than copy and paste completely, especially for folder names, file names, etc.and 64 indicate the number of threads.",
            "metadata": {
            "source": "run-pairsam-parse-sort.sh",
            "page": 3
        }
        
    },
    {
        "content": "9. run-cool2multirescool.sh\nRuns cooler coarsegrain to create multi-res cool file from a .cool file.\nInput : a cool file (.cool)\nOutput : a multires.cool file (.multires.cool)\nUsage\nRun the following in the container.\nrun-cool2multirescool.sh -i <input_cool> [-p <ncores>] [-o <output_prefix>] [-c <chunksize>] [-j] [-u custom_res] [-B]\n# input_cool : a (single-res) cool file with the highest resolution you want in the multi-res cool file\n# -p ncores: number of cores to use (default: 1)\n# -o output_prefix: prefix of the output multires.cool file (default: out)\n# -c chunksize : chunksize argument of cooler (e.g. default: 10000000)\n# -j : juicer resolutions (default: use HiGlass resolutions)\n# -u custom_res : custom resolutions separated by commas (e.g. 100000,200000,500000). The minimum of this set must match min_res (-r).\n# -B : no balancing/normalizations\n\nSet parameters according to the example:\nSuppose the input file is: ./output/003/cool_prefix_normalized.cool , the target is ./output/003/multirescool_prefix.mcool. Generate the following sample script:\n\nbash ./scripts/run-cool2multirescool.sh -i ./output/003/cool_prefix_normalized.cool -p 8 -o ./output/003/multirescool_prefix -c 10000000 -j -u 100000,200000,500000\n\nYou can install the tool, but do not do any additional operations.Please follow the example to generate rather than copy and paste completely, especially for folder names, file names, etc.and 64 indicate the number of threads.",
            "metadata": {
            "source": "run-pairsam-parse-sort.sh",
            "page": 3
        }
        
    }
]
